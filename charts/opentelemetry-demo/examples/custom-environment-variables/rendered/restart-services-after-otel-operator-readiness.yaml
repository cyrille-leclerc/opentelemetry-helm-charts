---
# Source: opentelemetry-demo/templates/restart-services-after-otel-operator-readiness.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: example-restart-services-after-otel-operator-is-ready
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-demo-0.39.0
    
    
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
---
# Source: opentelemetry-demo/templates/restart-services-after-otel-operator-readiness.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: example-restart-services-after-otel-operator-is-ready-default
  labels:
    helm.sh/chart: opentelemetry-demo-0.39.0
    
    
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: ["apiextensions.k8s.io"]
  resources: ["customresourcedefinitions"]
  verbs: ["get", "list", "watch"]
---
# Source: opentelemetry-demo/templates/restart-services-after-otel-operator-readiness.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: example-restart-services-after-otel-operator-is-ready-default
  labels:
    helm.sh/chart: opentelemetry-demo-0.39.0
    
    
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
subjects:
- kind: ServiceAccount
  name: example-restart-services-after-otel-operator-is-ready
  namespace: default
roleRef:
  kind: ClusterRole
  name: example-restart-services-after-otel-operator-is-ready-default
  apiGroup: rbac.authorization.k8s.io
---
# Source: opentelemetry-demo/templates/restart-services-after-otel-operator-readiness.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: example-restart-services-after-otel-operator-is-ready
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-demo-0.39.0
    
    
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch", "describe", "patch"] # grant "patch" to restart deployments and let otel-operator inject the configuration
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
# Source: opentelemetry-demo/templates/restart-services-after-otel-operator-readiness.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: example-restart-services-after-otel-operator-is-ready
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-demo-0.39.0
    
    
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
subjects:
- kind: ServiceAccount
  name: example-restart-services-after-otel-operator-is-ready
  namespace: default
roleRef:
  kind: Role
  name: example-restart-services-after-otel-operator-is-ready
  apiGroup: rbac.authorization.k8s.io
---
# Source: opentelemetry-demo/templates/restart-services-after-otel-operator-readiness.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: example-restart-services-after-otel-operator-is-ready
  labels:
    helm.sh/chart: opentelemetry-demo-0.39.0
    
    
    app.kubernetes.io/version: "2.1.3"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 3
  activeDeadlineSeconds: 900  # 15 minutes timeout
  template:
    spec:
      restartPolicy: Never
      serviceAccountName: example-restart-services-after-otel-operator-is-ready
      containers:
      - name: restart-services-after-otel-operator-is-ready
        image: alpine/k8s:1.31.13 # the rancher/kubectl image doesn't include 'sh'
        command:
        - /bin/sh
        - -c
        - |
          set -e
          echo "Starting OpenTelemetry Operator Instrumentationreadiness check..."

          echo "Waiting for OpenTelemetry Operator deployment..."
          timeout 600 sh -c 'until kubectl get deployment -l app.kubernetes.io/name=opentelemetry-operator --namespace default; do echo "Waiting for operator deployment..."; sleep 10; done'

          echo "Waiting for OpenTelemetry Operator to be available..."
          kubectl wait --for=condition=available deployment -l app.kubernetes.io/name=opentelemetry-operator --namespace default --timeout=600s || {
            echo "Operator deployment failed to become available. Checking status..."
            kubectl describe deployment -l app.kubernetes.io/name=opentelemetry-operator --namespace default
            exit 1
          }

          echo "Waiting for Instrumentation CRD..."
          timeout 300 sh -c 'until kubectl get crd instrumentations.opentelemetry.io; do echo "Waiting for Instrumentation CRD..."; sleep 5; done'
          kubectl wait --for=condition=established crd/instrumentations.opentelemetry.io --timeout=300s

          echo "OpenTelemetry Operator Instrumentation ready!"

          echo "Starting restart instrumented services..."
          for deployment in $(kubectl get deployments -n otel-demo -o jsonpath='{range .items[?(@.spec.template.metadata.annotations.instrumentation\.opentelemetry\.io/inject-sdk=="true")]}{.metadata.name}{" "}{end}'); do
            kubectl rollout restart deployment/$deployment -n otel-demo
          done
